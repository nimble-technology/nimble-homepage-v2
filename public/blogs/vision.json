{
  "title": "Vision for Composable AI",
  "author": "Anthony Isaacson",
  "createDate": "2024-01-13",
  "content": "## **Abstract**\n\nThe internet is the most powerful connective force in history. Billions of people across the globe communicate and transact in real-time. The data produced through our online activity powers the AI models that drive the digital economy.\n\nNimble is enabling an open economy for data and intelligence. Our composable AI protocol will provide a decentralized framework that enables AI models and data to be combined and reused. A network of interconnected AI agents, data providers, and compute resources replaces centralized platforms. Anyone can own, run, and train enterprise-grade AI over the decentralized network.\n\nIn the same way that Google made the world’s data accessible to all, Nimble aims to democratize the exchange of intelligence to enable permissionless innovation.\n\n\n## The Connected Era\n\nThe early internet was quite different from what we have today. In the days of Web 1.0, we created and shared content on a network of niche microsites. Publishing content on Web 1.0 was prohibitively complex, with users needing to learn an emerging technology just to post a photo or article. The content was read-only and mostly shared through plain old links, so reaching a large audience was rare.\n\nWhat use is owning your own corner of the internet if no one is listening?\n\nThe solution to these problems was the bright idea that spawned the modern internet - Web2. The answer to the fragmentation of Web 1.0 was consolidation. Rather than creating our website to host the content we create, we share our content on platforms dedicated to the medium to be shared.\n\nPlatforms dramatically simplify the way we interact with the web. Sharing a photo of your cat is just a few taps away, and the billions of users almost guarantee an audience.\n\nThe degree of consolidation has become extreme. In 2021, the top 6 tech platforms accounted for well over half of all traffic on the internet. Platforms have become synonymous with the type of content they distribute. YouTube owns video content. Google owns search. Twitch owns live streaming.\n\nExcept they don’t own them at all. YouTube doesn’t record videos. Google doesn’t write the text content they index. Twitch doesn’t livestream. What these platforms really own is us. The product they provide is access to an audience that we both embody and require. The undeniable simplicity of platforms comes at a cost.\n\nData about platform usage is carefully cataloged and sold to anyone with the money to pay for it. This data is routinely used as a lever to sway your purchase behavior, fueling incredibly accurate content recommendations.\n\nWe believe that Web 3.0 can serve as the foundation for a new Internet that combines the freedom of the early Internet with the utility of the modern platform-dominated Internet. This will require control over the powerful AI systems that generate the experiences of the modern web to be returned to the public. Doing so will enable a re-balancing of control away from tech monopolies and towards everyday internet users.\n\n\n#### **Requirements for Democratic AI**\n\nTwo requirements must be met to create this fairer internet\n\nFirst, contributing to the system must be sufficiently simple so small teams and individuals are not excluded. The AI systems behind today’s most powerful companies are complex. Training data are sourced from applications used by billions of people and collected by automated pipelines. Millions of dollars are spent on computing power to train models using these data sets.\n\nThe cost and complexity associated with these steps exclude virtually everyone, apart from an elite group of engineers and business people.\n\nSecond, the system must be completely open, accepting contributions from anyone at any level. An inclusive AI system would allow open contributions of three types:\n\n\n\n1. Data. A system should exist to allow participants to contribute data sets of any size to train the models on the network. Contributions in raw data, pre-processed data, and embeddings should be permitted.\n2. Compute. Participants should be able to contribute incremental computing power to train and serve models on the network. Bitcoin has become the most powerful computing network on earth through proof of work - Nimble aims to direct that computing power to serve and train models.\n3. Models. AI experts and developers should be able to contribute their models to the network to generate predictions or receive training through community data sets. Through composability, model outputs should be usable directly by end-users or incrementally by other models.\n\n\n## The Intelligence Economy\n\n\n#### **The Composable AI Protocol**\n\nNimble will democratize the economy for intelligence through composable AI. The protocol enables anyone to leverage and contribute to cutting-edge AI technology with minimal barriers to entry. Model predictions can be easily incorporated into traditional or decentralized applications across any domain through open APIs. Models can be networked together, consuming the outputs of other AI models through composability, producing powerful compound predictions. Participants can contribute training data to the network, distributing it to all models interested in consuming it. The network is decentralized and orchestrated under a single token ecosystem.\n\n\n## Protocol Overview\n\n\n### **Blockchain First**\n\nEvery component of our protocol is built on the blockchain. Since blockchains eliminate the need for trusted intermediate entities, they are the ideal technology for building a freer internet. Most importantly, they are fully decentralized, allowing users to own and control their data, audiences, and outcomes.\n\n\n### **Omnichain Compatibility**\n\nMuch of the blockchain ecosystem is highly fragmented today. To enable dApps from across the decentralized web to leverage insights from Nimble, our protocol’s outputs can be natively bridged to the most popular blockchains.\n\nAdditionally, traditional applications and enterprises can directly consume insights from Nimble models using our developer SDK.\n\n\n### **Three Markets**\n\nOur protocol consists of three decentralized markets that come together to accomplish our vision. These peer-to-peer markets submit trades to the blockchain to be verified by validators. Trades come in the form of transactions, orders, and proofs. Participants are rewarded only for valid trades, which motivates good behavior.\n\n**Data Market**\n\nTraining AI models is a data-intensive process, so consuming large amounts of data is a prerequisite for any successful system. To ensure fairness, Nimble must allow anyone to contribute data in exchange for token rewards.\n\nUsers place offer orders for their data sets and model parameters in the data market. When an order is met with a bid, validators reward the user in tokens. Data is passed from the user to the node in a privacy-preserving manner.\n\n**Computation Market**\n\nTwo main types of computation must occur to serve and maintain AI models on Nimble. First, data must be preprocessed to become usable by AI models. Next, models must be trained using the preprocessed data to generate inferences from prediction requests.\n\nThe Computation Market is a decentralized alternative to the data servers of centralized platforms. It works like a job recruitment market; a client has a query (job) in mind and looks for a validator with data and/or model (caliber) to answer it. The routers guarantee that the results provided by the validators are trustworthy.\n\n**Builder Market**\n\nExperienced AI developers can contribute models in exchange for token rewards on the builder market. Models from any domain can be run on Nimble. When models are queried by end-users, builders receive a portion of the network fees as a reward for their contribution.\n\nThis incentive plan encourages builders to submit high-quality, diverse models to the network. The more a model is used, the more the builder can earn from Nimble.\n\n\n## Composable AI Applications\n\n**Language Models**\n\nLarge language models (LLMs) like OpenAI’s ChatGPT use composable AI in the transformers that train and power their popular products.\n\nThe most common architecture used by LLMs is the Transformer Model. Transformers generate their output by relying on four different neural network layers. These four layers work together to generate a response to the user’s prompt.\n\n\n\n1. Embeddings layer. Converts user input into a machine-readable format called embeddings\n2. Feedforward layer. Transforms the user’s input to interpret higher-level abstractions, such as their intended meaning.\n3. Recurrent layer. Captures the relationship between the words in the user’s input.\n4. Attention mechanism. Focuses the model’s attention on the most important part of the input text.\n\nThese four components of transformers work together through composability to generate remarkable results.\n\nDevelopers can use Nimble’s composable AI protocol to deploy entire transformers or borrow layers from other models to invent their own novel and powerful applications. Composability on a permissionless protocol enables exciting growth in the field of LLMs.\n\n\n#### **Search Ranking**\n\nSearch engines use composable AI to produce meaningful results by interpreting a user’s intended search from their search terms and then returning an ordered list based on thousands of criteria.\n\nThere are billions of possible content items to return to the user, so creating a ranking of all possible items is not realistic. It would be too slow. Modern search companies leverage a composable AI method called the Two Tower model to accelerate search performance. The method has two stages:\n\n\n\n1. Retrieval (candidate generation). This model returns several hundred unranked items that match the user’s text query\n2. Ranking (re-ranking). This model looks over the returned list of items and considers all of their features in more detail to create a final list\n\nBy composing the results of multiple models together, a high-quality result can be quickly created for end users. Without composability, the results from the single models would either be too slow to be practical or fail to achieve the user’s expected levels of customization.\n\n**Anomaly Detection for Cybersecurity**\n\nModern cybersecurity programs leverage anomaly detection solutions to identify and prevent threats to their network and organization. Solutions like Intrusion Detection Systems (IDS) or Intrusion Prevention Systems (IPS) learn how connected devices (i.e., IoT cameras, printers, smart lighting) behave under normal conditions.\n\nWhen these devices are compromised by malware or used by a malicious actor, their behavior changes. IDS/IPS solutions can automatically block this behavior, increasing the network's security.\n\nThese tools rely on data-intensive machine learning techniques to function. A series of models can be leveraged through composable AI to prevent threats.\n\n\n\n1. Behavior learning model. Device behavior in the form of IP packets is fed to a machine learning model under normal conditions. This forms the device’s behavior baseline.\n2. Anomaly model. A separate machine learning model monitors IP over the production network, comparing live traffic to the baselines in real-time.\n\nSeparately, these models have zero business value. Together, they are the enabling technology of a multi-billion dollar industry. The business value is made possible only through composability.\n\n**Fraud Detection**\n\nUber uses composable AI to detect collusion between riders and drivers and prevent fraud. One common type of fraudulent behavior involves riders working with drivers to solicit rides using stolen credit cards. This results in a chargeback from the credit card company and can lead to lost revenue.\n\nTo detect this type of fraud, Uber employs a network of AI models to identify connections between riders and drivers. Affiliated users are more likely to be colluding to commit fraud than users who don’t know one another.\n\nUber employs multiple risk models and several checkpoints to detect fraud. Fraud scores derived from each model are used as features in downstream models, improving their accuracy.\n\nIn production environments tied to real business objectives, the quality of predictions from AI models can have tangible impacts on the bottom line. In these scenarios, composability is the key differentiator between a trivial AI model functioning as a pet project and a production system capable of saving the company significant amounts of money.\n\n\n### **The Intelligence Economy**\n\nThe platforms of Web2 made the Internet usable and accessible to all by rendering the complexity of computing and networking transparent. Now, they monopolize our online lives and erode our privacy.\n\nOur composable AI protocol will enable anyone to leverage and contribute to cutting-edge AI technology with minimal barriers to entry. By creating the economy for intelligence, Nimble will enable democratized AI that will bring Web3’s true utility to the mainstream digital landscape."
}